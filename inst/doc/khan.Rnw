\documentclass[a4paper]{article}
\usepackage[round]{natbib}
\usepackage{Sweave}
\usepackage{hyperref}
%% need no \usepackage{Sweave.sty}
%\usepackage{natbib}
%\usepackage{/usr/lib/R/share/texmf/Sweave}
%\VignetteIndexEntry{Classification of Cancer Types Using Gene Expression Data}
%\VignetteDepends{}
%\SweaveOpts{keep.source=FALSE}
\hypersetup{%
  pdftitle = {Classification of Cancer Types Using Gene Expression Data},
  pdfsubject = {package vignette},
  pdfauthor = {Zhu Wang},
%% change colorlinks to false for pretty printing
  colorlinks = {true},
  linkcolor = {blue},
  citecolor = {blue},
  urlcolor = {red},
  hyperindex = {true},
  linktocpage = {true},
}

\author{Zhu Wang \\
  Connecticut Children's Medical Center\\
  University of Connecticut School of Medicine\\
  zwang@connecticutchildrens.org}
\title{Classification of Cancer Types Using Gene Expression Data}
\begin{document}
\setkeys{Gin}{width=0.6\textwidth, keepaspectratio}
\date{}
\maketitle

This document presents data analysis similar to \cite{wang2011multi}  using R package \textbf{bst}. 
Classifying the small round blue cell tumors
(SRBCTs) of childhood into four categories is studied using gene expression
profiles \url{http://research.nhgri.nih.gov/microarray/Supplement/}.
 With 2,308 gene profiles in 63
training samples and 20 test samples, perfect
classification can be reached. We delete information not used in the analysis and set up the right data format. Take the logarithm
base 10 of the gene levels, then standardize
the results. We then select top 300 genes
based on a marginal relevance measure. 

<<echo=false,results=hide>>=
options(prompt = "R> ", continue = " ", width = 70, digits =4, useFancyQuotes = FALSE)
@
<<echo=TRUE, results=hide>>=
library("bst")
datafile <- system.file("extdata", "supplemental_data", package="bst")
dat0 <- read.delim(datafile, header=TRUE, skip=1)[,-(1:2)]
genename <- read.delim(datafile, header=TRUE, skip=1)[,(1:2)]
dat0 <- t(dat0)
dat1 <- dat0[rownames(dat0) %in% 
c("TEST.9", "TEST.13","TEST.5", "TEST.3", "TEST.11"),]
dat2 <- dat0[!rownames(dat0) %in% 
c("TEST.9", "TEST.13","TEST.5", "TEST.3", "TEST.11"),]
dat2 <- rbind(dat2, dat1)
train <- dat2[1:63,] ### training samples
test <- dat2[64:83,] ### test samples
train.classes <- substr(rownames(train), 1,2)
test.classes <- c("NB","RM","NB","EW","RM","BL","EW","RM","EW","EW","EW",
"RM","BL","RM","NB","NB","NB","NB","BL","EW")
train.classes <- as.numeric(factor(train.classes, levels=c("EW", "BL", "NB", "RM")))
test.classes <- as.numeric(factor(test.classes, levels=c("EW", "BL", "NB", "RM")))
### pre-processing training data: standardize predictors after log-transformation
train <- log10(train)
x <- train
meanx <- colMeans(x)
one <- rep(1,nrow(x))
normx <- sqrt(drop(one %*% (x^2)))
train <- scale(train, meanx, normx)
### compute a marginal relevance measure
tmp <- cbind(train, train.classes)
a0 <- b0 <- 0
  for(k in 1:length(table(train.classes))){
    tmp1 <- subset(tmp, tmp[,2309]==k)
    xc.bar <- colMeans(tmp1[,-2309])   ###average of gene j across class k 
    xa.bar <- colMeans(tmp[,-2309])    ###average of gene j across all samples
    a0 <- a0 + dim(tmp1)[1] * ((xc.bar - xa.bar)^2)
    b0 <- b0 + colSums((tmp[,-2309] - xc.bar)^2)
}
bw <- a0/b0
### select top 300 genes based on the ordered marginal relevance measure
npre <- 300
bw1 <- order(bw, decreasing=TRUE)[1:npre]
train <- train[,bw1]
### pre-processing test data: standardize predictors after log-transformation
### select the same 300 genes as in the training data
test <- log10(test)
test <- scale(test, meanx, normx)[, bw1]
test <- as.data.frame(test)
colnames(train) <- paste("x", 1:dim(train)[2], sep="")
colnames(test) <- paste("x", 1:dim(test)[2], sep="")
@

Multi-class HingeBoost with smoothing splines as base learner is applied to the
data. A 5-fold cross-validation is used for tuning parameter selection.
<<echo=TRUE, fig=TRUE, results=hide, eval=T>>=
m <- 30
set.seed(123)
dat.cvm <- cv.mhingebst(x=train, y=train.classes, balance=TRUE, K=5, 
ctrl = bst_control(mstop=m), family = "hinge", learner = "sm", type="misc", n.cores=2)
@

Multi-class HingeBoost is applied with boosting iteration 20 based on the cross-validation results.
Plot the evolution of the misclassification error on the test data versus the iteration counter, as the multi-class HingeBoost algorithm proceeds while working on the test set.
<<fig=TRUE, eval=T>>=
m1 <- 20
dat.m1 <- mhingebst(x=train, y=train.classes, ctrl = bst_control(mstop=m1),
 family = "hinge", learner = "sm")
risk.te1 <- predict(dat.m1, newdata=test, newy=test.classes, type="error")
plot(risk.te1, type="l", xlab="Iteration", ylab="Test Error")
@

Plot the evolution of the number of genes selected versus the iteration counter, as the multi-class HingeBoost algorithm proceeds while working on the training set.
<<fig=TRUE, eval=T>>=
plot(nsel(dat.m1, m1), ylab="No. Genes", xlab="Iteration", lty="solid", type="l")
@

Multi-class twin HingeBoost is applied.
Plot the evolution of the misclassification error on the test data versus the iteration counter, as the multi-class twin HingeBoost algorithm proceeds while working on the test set.
<<echo=TRUE, fig=TRUE, results=hide, eval=T>>=
m2 <- 20
xinit <- unlist(dat.m1$xselect)
xinit <- subset(xinit, !is.na(xinit))
dat.m2 <- mhingebst(x=train, y=train.classes, family = "hinge", learner = "sm",
ctrl = bst_control(mstop=m2, twinboost=TRUE, f.init=dat.m1$yhat, xselect.init=xinit)) 
risk.te2 <- predict(dat.m2,newdata=test,newy=test.classes,type="error")
plot(risk.te2, type="l", xlab="Iteration", ylab="Test Error")
@

Plot the evolution of the number of genes selected versus the iteration counter, as the multi-class twin HingeBoost algorithm proceeds while working on the training set.
<<fig=TRUE, eval=T>>=
plot(nsel(dat.m2, m2), ylab="No. Genes", xlab="Iteration", lty="solid", type="l")
@

@
%<<sessionInfo>>=
%sessionInfo();
%@
\bibliographystyle{plainnat}
\bibliography{bst}
\end{document}
